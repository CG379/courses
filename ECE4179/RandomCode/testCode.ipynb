{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: 1x1x5x5\n",
      "Output tensor:\n",
      "[30.0, 59.0, 31.0, 20.0, 4.0]\n",
      "[51.0, 48.0, 75.0, 11.0, 10.0]\n",
      "[96.0, 97.0, 128.0, 66.0, 26.0]\n",
      "[60.0, 36.0, 87.0, 32.0, 20.0]\n",
      "[48.0, 20.0, 88.0, 17.0, 36.0]\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def transposed_conv_output(input_tensor, kernel, stride=1, padding=0, dilation=1, output_padding=0):\n",
    "    # Convert to torch tensors if they aren't already\n",
    "    input_tensor = torch.tensor(input_tensor, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimension\n",
    "    kernel = torch.tensor(kernel, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel dimensions\n",
    "\n",
    "    # Get the dimensions\n",
    "    batch_size, in_channels, h_in, w_in = input_tensor.shape\n",
    "    out_channels, _, k_h, k_w = kernel.shape\n",
    "\n",
    "    # Calculate output size\n",
    "    h_out = (h_in - 1) * stride - 2 * padding + dilation * (k_h - 1) + output_padding + 1\n",
    "    w_out = (w_in - 1) * stride - 2 * padding + dilation * (k_w - 1) + output_padding + 1\n",
    "    \n",
    "    print(f\"Output shape: {batch_size}x{out_channels}x{h_out}x{w_out}\")\n",
    "\n",
    "    # Perform transposed convolution\n",
    "    output = F.conv_transpose2d(input_tensor, kernel, stride=stride, padding=padding, dilation=dilation, output_padding=output_padding)\n",
    "\n",
    "    # Convert back to a list for easier manipulation outside of PyTorch if needed\n",
    "    output_list = output.squeeze().tolist()  # Remove batch and channel dimensions for simplicity\n",
    "\n",
    "    return output_list, (h_out, w_out)\n",
    "\n",
    "# Example usage:\n",
    "input_tensor = [\n",
    "    [6, 1, 2],\n",
    "    [3, 3, 0],\n",
    "    [6, 1, 4]\n",
    "]\n",
    "\n",
    "kernel = [\n",
    "    [5, 9, 2],\n",
    "    [6, 0, 5],\n",
    "    [8, 2, 9]\n",
    "]\n",
    "\n",
    "output, (height, width) = transposed_conv_output(input_tensor, kernel)\n",
    "print(\"Output tensor:\")\n",
    "for row in output:\n",
    "    print(row)\n",
    "print(output[3][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y[0] = w1*0 + w2*x1 + w3*x2 + w4*x3\n",
      "y[1] = w1*x1 + w2*x2 + w3*x3 + w4*x4\n",
      "y[2] = w1*x2 + w2*x3 + w3*x4 + w4*x5\n",
      "y[3] = w1*x3 + w2*x4 + w3*x5 + w4*0\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "def symbolic_convolution(x_len, w_len, padding, stride, dilation):\n",
    "    # Create symbolic variables for x and w starting from 1\n",
    "    x = sp.symbols(f'x1:{x_len+1}')\n",
    "    w = sp.symbols(f'w1:{w_len+1}')\n",
    "    \n",
    "    # Calculate the effective kernel size considering dilation\n",
    "    effective_kernel_size = (w_len - 1) * dilation + 1\n",
    "    \n",
    "    # Calculate the output length\n",
    "    out_len = (x_len + 2 * padding - effective_kernel_size) // stride + 1\n",
    "    \n",
    "    y = []\n",
    "    for i in range(out_len):\n",
    "        start = i * stride - padding\n",
    "        terms = []\n",
    "        for j in range(w_len):\n",
    "            idx = start + j * dilation\n",
    "            # Adjust indexing to start from 1\n",
    "            if 1 <= idx+1 <= x_len:  # Check if index is within the original input bounds\n",
    "                terms.append(f\"{w[j]}*{x[idx]}\")\n",
    "            elif idx == -1 or idx == x_len:  # Edge cases for padding\n",
    "                terms.append(f\"{w[j]}*0\")  # Symbolic representation of zero padding\n",
    "        \n",
    "        # Join terms with '+' for addition in convolution\n",
    "        y_element = ' + '.join(terms).replace(' + 0', '')  # Remove zero terms for clarity\n",
    "        y.append(y_element if y_element else '0')  # If all terms were zero, output '0'\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Example usage:\n",
    "x_length = 5  # Length of x\n",
    "w_length = 4  # Length of w\n",
    "pad = 1  # Padding\n",
    "s = 1  # Stride\n",
    "d = 1  # Dilation\n",
    "\n",
    "symbolic_output = symbolic_convolution(x_length, w_length, pad, s, d)\n",
    "for i, elem in enumerate(symbolic_output):\n",
    "    print(f\"y[{i}] = {elem}\")\n",
    "\n",
    "\n",
    "\n",
    "# w 2 n e w = w_n − ( 0.5 dL/dw_n + 0.4 sign(w_n) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of FLOPs for scenario 1 (Group Convolution) (write as a power of 2): 2^19\n",
      "Enter the number of FLOPs for scenario 2 (Ordinary Convolution) (write as a power of 2): 2^23\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_flops(co, ho, wo, ck, hk, wk, groups=1):\n",
    "    # FLOPs calculation for both scenarios\n",
    "    # co: number of output channels\n",
    "    # ho, wo: output height and width\n",
    "    # ck: number of channels in kernel (input channels for ordinary conv, input channels // groups for group conv)\n",
    "    # hk, wk: kernel height and width\n",
    "    # groups: number of groups for group convolution, 1 for ordinary convolution\n",
    "    \n",
    "    flops = co * ho * wo * ck * hk * wk\n",
    "    if groups > 1:\n",
    "        flops //= groups  # Adjust FLOPs for group convolution\n",
    "    return math.log2(flops)\n",
    "\n",
    "# Given parameters\n",
    "\n",
    "\n",
    "co = 4  # Number of output feature maps or channels for both scenarios for simplicity in comparison\n",
    "ho = wo = 32  # Output height and width\n",
    "ck_scenario_1 = 128  # For group convolution, typically input_channels // groups\n",
    "ck_scenario_2 = 512  # For ordinary convolution, typically equals input_channels\n",
    "hk = wk = 2  # Kernel height and width\n",
    "\n",
    "# Scenario 1: Group Convolution\n",
    "flops_scenario_1 = calculate_flops(co, ho, wo, ck_scenario_1, hk, wk, groups=4)  # Assuming 4 groups for example\n",
    "\n",
    "# Scenario 2: Ordinary Convolution\n",
    "flops_scenario_2 = calculate_flops(co, ho, wo, ck_scenario_2, hk, wk)\n",
    "\n",
    "print(f\"Enter the number of FLOPs for scenario 1 (Group Convolution) (write as a power of 2): 2^{int(flops_scenario_1)}\")\n",
    "print(f\"Enter the number of FLOPs for scenario 2 (Ordinary Convolution) (write as a power of 2): 2^{int(flops_scenario_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Feature 1:\n",
      "[[-1  5  2  0  2]\n",
      " [ 7 -9  7 -9  1]\n",
      " [-8  8 -3 -8  7]\n",
      " [-7  3  8  8 -3]\n",
      " [-9  4 -8 -9 -5]]\n",
      "\n",
      "Input Feature 2:\n",
      "[[-9  2 -2 -4  6]\n",
      " [ 3 -9 -3  9 -6]\n",
      " [-6  1  6  2 -6]\n",
      " [ 5 -2 -9  1 -6]\n",
      " [ 6 -4 -8  4  0]]\n",
      "\n",
      "Kernel 1:\n",
      "[[ 0 -1  2]\n",
      " [ 0 -1  2]\n",
      " [ 0 -1  2]]\n",
      "\n",
      "Kernel 2:\n",
      "[[-2  0  1]\n",
      " [-2  0  1]\n",
      " [-2  0  1]]\n",
      "\n",
      "Output 1:\n",
      "[[  8. -40.  37.]\n",
      " [ 22. -30.  19.]\n",
      " [-21. -15.   7.]]\n",
      "\n",
      "Output 2:\n",
      "[[ 25.  19.  -8.]\n",
      " [-10.  32.  -6.]\n",
      " [-21.  17.  10.]]\n",
      "\n",
      "Final Output:\n",
      "[[ 33. -21.  29.]\n",
      " [ 12.   2.  13.]\n",
      " [-42.   2.  17.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve2d(image, kernel, stride=1, padding=0, dilation=1):\n",
    "    # Get dimensions\n",
    "    h_img, w_img = image.shape\n",
    "    h_kern, w_kern = kernel.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    h_out = (h_img - h_kern + 2 * padding) // stride + 1\n",
    "    w_out = (w_img - w_kern + 2 * padding) // stride + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((h_out, w_out))\n",
    "    \n",
    "    # Pad the image if necessary\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, padding, mode='constant')\n",
    "    \n",
    "    # Perform convolution\n",
    "    for i in range(h_out):\n",
    "        for j in range(w_out):\n",
    "            output[i, j] = np.sum(image[i*stride:i*stride+h_kern, j*stride:j*stride+w_kern] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Input feature maps (5x5 each)\n",
    "input_feature1 = [\n",
    "    [-1, 5,2,0\t,2],\n",
    "    [7,-9,7,-9 ,1],\n",
    "    [-8 ,8,-3,-8,7],\n",
    "    [-7 ,3,8,8,-3 ],\n",
    "    [-9,4,-8 ,-9 ,-5]\n",
    "]\n",
    "\n",
    "input_feature2 = [\n",
    "    [-9,2,-2,-4,6],\n",
    "    [3,-9,-3,9,-6 ],\n",
    "    [-6,1,6,2,-6 ],\n",
    "    [5,-2 ,-9,1,-6 ],\n",
    "    [6,-4,-8,4,0]\n",
    "]\n",
    "\n",
    "# Kernels (3x3 each)\n",
    "kernel1 = [\n",
    "    [0, -1, 2],\n",
    "    [0, -1, 2],\n",
    "    [0, -1, 2]\n",
    "]\n",
    "\n",
    "kernel2 = [\n",
    "    [-2, 0, 1],\n",
    "    [-2, 0, 1],\n",
    "    [-2, 0, 1]\n",
    "]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "input_feature1 = np.array(input_feature1)\n",
    "input_feature2 = np.array(input_feature2)\n",
    "kernel1 = np.array(kernel1)\n",
    "kernel2 = np.array(kernel2)\n",
    "\n",
    "# Perform convolution for each channel\n",
    "output1 = convolve2d(input_feature1, kernel1)\n",
    "output2 = convolve2d(input_feature2, kernel2)\n",
    "\n",
    "# Sum the outputs to get the final result\n",
    "final_output = output1 + output2\n",
    "\n",
    "print(\"Input Feature 1:\")\n",
    "print(input_feature1)\n",
    "print(\"\\nInput Feature 2:\")\n",
    "print(input_feature2)\n",
    "print(\"\\nKernel 1:\")\n",
    "print(kernel1)\n",
    "print(\"\\nKernel 2:\")\n",
    "print(kernel2)\n",
    "print(\"\\nOutput 1:\")\n",
    "print(output1)\n",
    "print(\"\\nOutput 2:\")\n",
    "print(output2)\n",
    "print(\"\\nFinal Output:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X:\n",
      "[[ 2 -1 -2]\n",
      " [-1  1 -1]]\n",
      "\n",
      "Weight matrix Wq:\n",
      "[[-2  0  0]\n",
      " [ 2 -1  1]\n",
      " [ 0 -1  0]]\n",
      "\n",
      "Weight matrix Wk:\n",
      "[[-1 -2  1]\n",
      " [ 0  0  0]\n",
      " [-2 -2 -2]]\n",
      "\n",
      "Weight matrix Wv:\n",
      "[[ 1  1  1]\n",
      " [ 2  0 -1]\n",
      " [ 1  2  2]]\n",
      "\n",
      "Query matrix Q:\n",
      "[[-6  3 -1]\n",
      " [ 4  0  1]]\n",
      "\n",
      "Key matrix K:\n",
      "[[2 0 6]\n",
      " [3 4 1]]\n",
      "\n",
      "Value matrix V:\n",
      "[[-2 -2 -1]\n",
      " [ 0 -3 -4]]\n",
      "\n",
      "Attention scores:\n",
      "[[-18  -7]\n",
      " [ 14  13]]\n",
      "\n",
      "Attention weights (after softmax):\n",
      "[[1.67014218e-05 9.99983299e-01]\n",
      " [7.31058579e-01 2.68941421e-01]]\n",
      "\n",
      "Output Z:\n",
      "[[-3.34028437e-05 -2.99998330e+00 -3.99994990e+00]\n",
      " [-1.46211716e+00 -2.26894142e+00 -1.80682426e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Input matrices\n",
    "X = np.array([\n",
    "    [2, -1, -2],\n",
    "    [-1, 1, -1]\n",
    "])\n",
    "\n",
    "Wq = np.array([\n",
    "    [-2, 0, 0],\n",
    "    [2, -1, 1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "Wk = np.array([\n",
    "    [-1, -2, 1],\n",
    "    [0, 0, 0],\n",
    "    [-2, -2, -2]\n",
    "])\n",
    "\n",
    "Wv = np.array([\n",
    "    [1, 1, 1],\n",
    "    [2, 0, -1],\n",
    "    [1, 2, 2]\n",
    "])\n",
    "\n",
    "# Calculate Q, K, and V\n",
    "Q = np.dot(X, Wq)\n",
    "K = np.dot(X, Wk)\n",
    "V = np.dot(X, Wv)\n",
    "\n",
    "# Calculate attention scores\n",
    "attention_scores = np.dot(Q, K.T)\n",
    "\n",
    "# Apply softmax to get attention weights\n",
    "attention_weights = softmax(attention_scores)\n",
    "\n",
    "# Calculate the final output Z\n",
    "Z = np.dot(attention_weights, V)\n",
    "\n",
    "# Print results\n",
    "print(\"Input X:\")\n",
    "print(X)\n",
    "print(\"\\nWeight matrix Wq:\")\n",
    "print(Wq)\n",
    "print(\"\\nWeight matrix Wk:\")\n",
    "print(Wk)\n",
    "print(\"\\nWeight matrix Wv:\")\n",
    "print(Wv)\n",
    "print(\"\\nQuery matrix Q:\")\n",
    "print(Q)\n",
    "print(\"\\nKey matrix K:\")\n",
    "print(K)\n",
    "print(\"\\nValue matrix V:\")\n",
    "print(V)\n",
    "print(\"\\nAttention scores:\")\n",
    "print(attention_scores)\n",
    "print(\"\\nAttention weights (after softmax):\")\n",
    "print(attention_weights)\n",
    "print(\"\\nOutput Z:\")\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the loss with respect to weights (dL/dw):\n",
      "[[ 18.5 -19. ]\n",
      " [-10.5   6. ]]\n",
      "Updated weights (w_new):\n",
      "[[ 0.15 -0.1 ]\n",
      " [ 0.05  0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input image x (3x3 matrix)\n",
    "x = np.array([[-1.0, 2.0, -2.0],\n",
    "              [-1.0, -2.0, 0.0],\n",
    "              [2.0, 2.0, 1.0]])\n",
    "\n",
    "# Convolution weights w (2x2 matrix)\n",
    "w = np.array([[2.0, -2.0],\n",
    "              [-1.0, 1.0]])\n",
    "\n",
    "# Gradient of the loss with respect to the output ∇yL (2x2 matrix)\n",
    "dL_dy = np.array([[-3.5, 5.0],\n",
    "                  [1.0, -3.0]])\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.1\n",
    "\n",
    "# Initialize gradient of the loss with respect to weights (2x2 matrix)\n",
    "dL_dw = np.zeros((2, 2))\n",
    "\n",
    "# Compute the gradient of the loss with respect to each weight\n",
    "# For w1: the top-left corner of the input contributes to y1 and y2\n",
    "dL_dw[0, 0] = dL_dy[0, 0] * x[0, 0] + dL_dy[0, 1] * x[0, 1] + dL_dy[1, 0] * x[1, 0] + dL_dy[1, 1] * x[1, 1]\n",
    "\n",
    "# For w2: the top-right corner of the input contributes to y1 and y2\n",
    "dL_dw[0, 1] = dL_dy[0, 0] * x[0, 1] + dL_dy[0, 1] * x[0, 2] + dL_dy[1, 0] * x[1, 1] + dL_dy[1, 1] * x[1, 2]\n",
    "\n",
    "# For w3: the bottom-left corner of the input contributes to y1 and y2\n",
    "dL_dw[1, 0] = dL_dy[0, 0] * x[1, 0] + dL_dy[0, 1] * x[1, 1] + dL_dy[1, 0] * x[2, 0] + dL_dy[1, 1] * x[2, 1]\n",
    "\n",
    "# For w4: the bottom-right corner of the input contributes to y1 and y2\n",
    "dL_dw[1, 1] = dL_dy[0, 0] * x[1, 1] + dL_dy[0, 1] * x[1, 2] + dL_dy[1, 0] * x[2, 1] + dL_dy[1, 1] * x[2, 2]\n",
    "\n",
    "# Now, we have dL_dw which contains the gradients of the loss with respect to w1, w2, w3, and w4\n",
    "\n",
    "print(\"Gradient of the loss with respect to weights (dL/dw):\")\n",
    "print(dL_dw)\n",
    "\n",
    "# Update the weights using gradient descent\n",
    "w_new = w - eta * dL_dw\n",
    "\n",
    "# Round the updated weights to two decimal places\n",
    "w_new = np.round(w_new, 2)\n",
    "\n",
    "print(\"Updated weights (w_new):\")\n",
    "print(w_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE4179",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
